# OKRs - May 2026

## Objective 1: Make the experience for external model developers/metric developers good

*Use Kigali workshop as a goal for this. Will be assessed after Kigali.*

### Key Results

- Have both one R model and a Python model fully working through new chapkit system (new model integration system)
- Have several external people succeed in using our demo databases (can be measured on workshop, e.g. most should manage to set it up before the workshop)
- Have a case of users using climate app/tools together with chap-platform (with tutorial)
- Have production ready docker images for whole ecosystem
- Receive and integrate at least two externally contributed models (from someone outside UIO)
- Same for metric
- Same for visualizations
- Someone implementing their model without our help or input (except pointing to tutorials and/or improving them)
- One case of someone using the new metric system for something useful

## Objective 2: Move towards useful predictive models

*Will be assessed May 1, 2026*

### Key Results

- Deploy at least one prediction model that clearly outperforms existing models (in one country/use-case)
- Integrate seasonal forecast data into operational models (have one model that uses seasonal forecasts)
- Implement explainable AI features for at least one model type
- Launch first version of auto-ML system (have at least one public model that uses auto-ml)
- Have a good use case of a country with good data that we do something meaningful with (in terms of modeling with local data)
- Be able to use multi-resolution data (have a system for harmonizing different time-scales)
- Have an example/prototype of using population-weighting in a model (before aggregating)
- Get a good public dataset from open dengue (have one publicly available dataset that we have harmonized)
- Same for malaria

## Objective 3: Improve user engagement through capacity and documentation

### Key Results

- Have 8 cases (we already have one) of someone doing a good evaluation using metrics (an evaluation that makes sense and provides some useful insight)
- At least 20 posts on CoP
- Have gotten feedback from 3 MoH (some proof of engagement)
- Tutorials: have tutorials on metrics, integrating new models, tutorial for someone not knowing anything about modelling (in general better documentation than we had before), documentation on how to sell/communicate chap to MOH, tutorial on using climate data/tools with models (chap-platform)
- Secure collaboration with 1 external project using CHAP platform

## Objective 4: Advance Research Impact and Knowledge Dissemination

### Key Results

- Complete CHAP flagship paper as finished draft ready for submission
- Conduct 1-2 advocacy activities (conferences, presentations, publications)
- Halvard completes ethics course
- Have more engagement than before from the outside: Increase external visibility (define metric: citations, mentions, downloads)
- Herman need to publish at least one paper

## Other Health Metrics

- We should know and capture if users have use-cases we currently are not focusing on that we should focus on
- Respond to users using chap platform, modeling app, climate tools when they have problems
- Being able to help external people integrating metrics, models, vis, climate tools, etc.
- Be confident that we have enough tests and processes to avoid breaking stuff badly
- We can get an evaluation from quality lead from dhis2
- Keep on track with tasks that are under-prioritized
- Have a list of things we need to remind ourselves about (who is in charge of this?)
- Always make documentation, some tests and tutorials for new features/functionalities
- Every feature/product have one responsible (and should be clear who that is)
